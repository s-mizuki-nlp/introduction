{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset class implementation: Case study for sentiment text corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this document, we will implement the Dataset class that preprocesses sentiment-annotated text corpora.\n",
    "* Raw data is given as the NDJSON dataset. Each line represents the single sample; `text` field and `sentiment` field.\n",
    "\n",
    "```\n",
    "{\"text\": \"This is first text\", \"sentiment\": \"positive\"}\n",
    "{\"text\": \"This is second text\", \"sentiment\": \"negative\"}\n",
    "{\"text\": \"That's all\", \"sentiment\": \"positive\"}\n",
    "```\n",
    "\n",
    "* Let's say We want to apply following pre-processing.\n",
    "    1. tokenization\n",
    "    2. word-to-index conversion\n",
    "    3. sentiment class-to-index conversion.\n",
    "* What we expect after preprocessing is as follows.\n",
    "\n",
    "```\n",
    "{\"text:\" \"This is first text\", \"sentiment\": \"positive\", \"sequence\": [\"This\", \"is\", \"first\", \"text\"], \"token_ids: [1, 2, 3, 4], \"sentiment\": \"positive\", \"ground_truth\": 0}\n",
    "{\"text\": \"This is second ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to design the Dataset class\n",
    "* Widely accepted best practice is to decouple and modularize the preprocessing function as the transformation function.\n",
    "* With that in our mind, we will implement the dataset class that has two features: 1) data (NDJSON) read and 2) sequential application of transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Minimum requirements for Dataset class are as follows.\n",
    "    1. Inherit `torch.utils.data.Dataset` class.\n",
    "    2. Implement `__len__()` method.\n",
    "        * It tells how many samples are in the dataset.\n",
    "    3. Implement `__getitem__()` method.\n",
    "* In addition to these requirements, we will implement following methods.\n",
    "    1. `sample_loader()` method. It will return the iterable of samples.\n",
    "    2. `transform()` method. It will apply the given transformation functions sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable, Any\n",
    "import io, json\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path_like: str, transform_functions: Dict[str, Callable[[Dict[str, Any]], Dict[str, Any]]] = None):\n",
    "        self.path_like = path_like\n",
    "        self._samples = list(self.sample_loader())\n",
    "        self._transform_functions = transform_functions\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self._samples[idx]\n",
    "        preprocessed = self.transform(sample)\n",
    "        return preprocessed\n",
    "    \n",
    "    def sample_loader(self):\n",
    "        if isinstance(self.path_like, str):\n",
    "            ifs = io.open(self.path_like, mode=\"r\")\n",
    "        else:\n",
    "            ifs = self.path_like\n",
    "        for str_json in ifs:\n",
    "            yield json.loads(str_json.strip())\n",
    "        ifs.close()\n",
    "    \n",
    "    def transform(self, sample: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        if self._transform_functions is None:\n",
    "            return sample\n",
    "        \n",
    "        for output_field_name, transform_function in self._transform_functions.items():\n",
    "            sample[output_field_name] = transform_function(**sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See if it works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = \"\"\"\n",
    "{\"text\": \"This is first text\", \"sentiment\": \"positive\"}\n",
    "{\"text\": \"This is second text\", \"sentiment\": \"negative\"}\n",
    "{\"text\": \"That's all\", \"sentiment\": \"positive\"}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = io.StringIO(corpora)\n",
    "dataset = SentimentDataset(path_like=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Congratulations! You successfully implemented your own dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 3\n",
      "first sample: {'text': 'This is first text', 'sentiment': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"#samples: {len(dataset)}\")\n",
    "print(f\"first sample: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing transform functions\n",
    "* This is somewhat straitforward.\n",
    "* Hint: You should use np.array instead of list for numeric types. otherwise DataLoader (in default settings) won't transform to tensors as expected.\n",
    "* (ToDo: It is better parametrizing which field is used as the input of funciton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def whitespace_tokenizer(text, **kwargs):\n",
    "    return text.split(\" \")\n",
    "\n",
    "def token_to_index_converter(sequence, **kwargs):\n",
    "    mapper = {\n",
    "        \"This\": 0,\n",
    "        \"is\": 1,\n",
    "        \"first\": 2,\n",
    "        \"text\": 3\n",
    "    }\n",
    "    return np.array([mapper.get(token, -1) for token in sequence])\n",
    "\n",
    "def sentiment_to_index_converter(sentiment, **kwargs):\n",
    "    mapper = {\n",
    "        \"positive\": 0,\n",
    "        \"negative\": 1\n",
    "    }\n",
    "    return mapper[sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See if transformation works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = io.StringIO(corpora)\n",
    "transform_functions = OrderedDict() # order: tokenize > token-to-index > sentiment-to-index\n",
    "transform_functions[\"sequence\"] = whitespace_tokenizer\n",
    "transform_functions[\"token_ids\"] = token_to_index_converter\n",
    "transform_functions[\"ground_truth\"] = sentiment_to_index_converter\n",
    "\n",
    "dataset = SentimentDataset(path_like=p, transform_functions=transform_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Congratulations! You implemented your own preprocessing along with dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ground_truth': 0,\n",
      " 'sentiment': 'positive',\n",
      " 'sequence': ['This', 'is', 'first', 'text'],\n",
      " 'text': 'This is first text',\n",
      " 'token_ids': array([0, 1, 2, 3])}\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset[0], compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appenidix: DataLoader will do almost everything\n",
    "* shuffle, chunk, and conversion to tensor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ground_truth': tensor([0, 1]),\n",
      " 'sentiment': ['positive', 'negative'],\n",
      " 'sequence': [('This', 'This'), ('is', 'is'), ('first', 'second'),\n",
      "              ('text', 'text')],\n",
      " 'text': ['This is first text', 'This is second text'],\n",
      " 'token_ids': tensor([[ 0,  1,  2,  3],\n",
      "        [ 0,  1, -1,  3]])}\n",
      "---\n",
      "{'ground_truth': tensor([0]),\n",
      " 'sentiment': ['positive'],\n",
      " 'sequence': [(\"That's\",), ('all',)],\n",
      " 'text': [\"That's all\"],\n",
      " 'token_ids': tensor([[-1, -1]])}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    pprint(batch, compact=True)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
